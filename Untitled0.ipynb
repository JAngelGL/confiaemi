{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKcCJeX2kaK3",
        "outputId": "0b02bb9b-5729-45e7-93f8-2457ee0aea28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 0 B/110 kB 0%] [Connected to\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 110 kB/110 kB 99%] [2 InRele\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [2 InRelease 3,626 B/3,626 B 100%] [Conne\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.52\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.52\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\u001b[33m\r0% [4 InRelease 12.7 kB/119 kB 11%] [Connected to ppa.launchpadcontent.net (185\u001b[0m\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,223 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,078 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [518 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,247 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,340 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 8,017 kB in 2s (5,016 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "29 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=f7262ef6fb6881c30577a0343bdc31f9f5549ee8a99330f6e315d01defea7f7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQciKbaYkb_M",
        "outputId": "f04bccdc-1a10-40da-8a78-b5966c309474"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo cruise2.csv renombrado como cruise2_descartado.csv\n",
            "Archivo cruise3.csv renombrado como cruise3_descartado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "# Inicializa una sesión de Spark\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"RenombrarArchivosCSV\").getOrCreate()\n",
        "\n",
        "# Directorio que contiene los archivos CSV\n",
        "directorio = \"ruta\"\n",
        "\n",
        "# Listas para almacenar los nombres de los archivos\n",
        "archivos_con_1 = []\n",
        "archivos_descartados = []\n",
        "\n",
        "# Función para verificar si un archivo debe ser renombrado\n",
        "def debe_renombrar(archivo):\n",
        "    try:\n",
        "        # Lee el archivo CSV en un DataFrame de Spark\n",
        "        df = spark.read.csv(os.path.join(directorio, archivo), header=True, inferSchema=True)\n",
        "        # Verifica si hay al menos un 1 en la columna \"Stable cruise\"\n",
        "        if 1 in df.select(\"COL_uno\").rdd.flatMap(lambda x: x).collect():\n",
        "            archivos_con_1.append(archivo)\n",
        "        else:\n",
        "            archivos_descartados.append(archivo)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo {archivo}: {str(e)}\")\n",
        "\n",
        "# Renombra los archivos y registra en las listas correspondientes\n",
        "for archivo in archivos:\n",
        "    debe_renombrar(archivo)\n",
        "\n",
        "# Cierra la sesión de Spark\n",
        "spark.stop()\n",
        "\n",
        "# Imprime los nombres de los archivos en las listas\n",
        "print(\"Archivos con al menos un 1:\", archivos_con_1,)\n",
        "print(\"Archivos descartados:\", archivos_descartados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR5267vcmL0g",
        "outputId": "8e3235df-00ab-4ba9-cf95-0bda78d3ac93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos con al menos un 1: ['cruise4.csv', 'cruise1.csv']\n",
            "Archivos descartados: ['cruise2.csv', 'cruise3.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qirRi_6EoAbq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQfd26Ppncs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}